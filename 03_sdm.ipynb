{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7yl4r/0ad-unit-net/blob/master/03_sdm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify this section as needed.\n",
        "\n",
        "# ==============================================================================\n",
        "# === directory setup\n",
        "# ==============================================================================\n",
        "# If using google colab and google drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_DIR = '/content/drive/MyDrive/GSoC_SDM_Project'\n",
        "\n",
        "# === if using local machine\n",
        "# PROJECT_DIR = './'\n",
        "#import os\n",
        "#if not os.path.exists(PROJECT_DIR):\n",
        "#    os.makedirs(PROJECT_DIR)\n",
        "\n",
        "# ==============================================================================\n",
        "# ==============================================================================\n",
        "# === spatial coverage\n",
        "# ==============================================================================\n",
        "LATMIN = 24.11637699635014\n",
        "LATMAX = 26.11949526731449\n",
        "LONMIN = -82.51572158798965\n",
        "LONMAX = -79.61106009492724\n",
        "# =============================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8qnaD3FFI9A",
        "outputId": "8a84c224-8d51-4b7b-b87f-0658ffea8c4a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "duORdW0vAiYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534e44fa-84d6-4b47-c728-49bf683e7356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.3.1)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.6.15)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4) (1.6.4.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies TODO: are all these needed?\n",
        "!pip install  rasterio pandas geopandas matplotlib  requests xarray netCDF4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries & setup\n"
      ],
      "metadata": {
        "id": "PA9meCsJEJJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: are all these imports needed?\n",
        "\n",
        "\n",
        "# Standard library imports\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "import warnings\n",
        "\n",
        "# Third-party library imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import seaborn as sns\n",
        "import xarray as xr\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn import metrics, svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "eroPo3d2EEx4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SDM Class for Marine species\n"
      ],
      "metadata": {
        "id": "_Kl5xGZ72gLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MarineSpeciesDistributionModel:\n",
        "    \"\"\"\n",
        "    A Species Distribution Model for marine species using One-Class SVM\n",
        "    Similar to the scikit-learn species distribution example but adapted for marine data\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nu=0.1, kernel='rbf', gamma=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the SDM model\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        nu : float, default=0.1\n",
        "            An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors\n",
        "        kernel : str, default='rbf'\n",
        "            Kernel type for SVM\n",
        "        gamma : float, default=0.5\n",
        "            Kernel coefficient for 'rbf'\n",
        "        \"\"\"\n",
        "        self.nu = nu\n",
        "        self.kernel = kernel\n",
        "        self.gamma = gamma\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.feature_names = None\n",
        "        self.species_name = None\n",
        "\n",
        "    def add_environmental_data(self, df, raster_path, column_name='environmental_var',\n",
        "                              lat_col='decimalLatitude', lon_col='decimalLongitude'):\n",
        "        \"\"\"\n",
        "        Add environmental data from raster to occurrence dataframe\n",
        "        \"\"\"\n",
        "        df_result = df.copy()\n",
        "\n",
        "        try:\n",
        "            with rasterio.open(raster_path) as src:\n",
        "                coords = [(row[lon_col], row[lat_col]) for _, row in df.iterrows()]\n",
        "                sampled_values = list(src.sample(coords))\n",
        "                values = [val[0] if val[0] != src.nodata else np.nan for val in sampled_values]\n",
        "                df_result[column_name] = values\n",
        "\n",
        "            valid_count = df_result[column_name].notna().sum()\n",
        "            print(f\"Added {column_name}: {valid_count}/{len(df_result)} valid values\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding environmental data from {raster_path}: {e}\")\n",
        "            df_result[column_name] = np.nan\n",
        "\n",
        "        return df_result\n",
        "\n",
        "    def prepare_data(self, df, environmental_cols, lat_col='decimalLatitude',\n",
        "                    lon_col='decimalLongitude', test_size=0.2, random_state=42):\n",
        "        \"\"\"\n",
        "        Prepare training and testing data from occurrence dataframe\n",
        "        \"\"\"\n",
        "        df_clean = df.dropna(subset=environmental_cols)\n",
        "\n",
        "        if len(df_clean) == 0:\n",
        "            raise ValueError(\"No valid data points after removing missing values\")\n",
        "\n",
        "\n",
        "        coords = df_clean[[lat_col, lon_col]].values\n",
        "        env_features = df_clean[environmental_cols].values\n",
        "\n",
        "\n",
        "        X_train, X_test, coords_train, coords_test = train_test_split(\n",
        "            env_features, coords, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        self.feature_names = environmental_cols\n",
        "\n",
        "        return {\n",
        "            'X_train': X_train,\n",
        "            'X_test': X_test,\n",
        "            'coords_train': coords_train,\n",
        "            'coords_test': coords_test,\n",
        "            'df_clean': df_clean\n",
        "        }\n",
        "\n",
        "    def fit(self, X_train):\n",
        "        \"\"\"\n",
        "        Fit the One-Class SVM model\n",
        "        \"\"\"\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "        print(\"Fitting One-Class SVM...\")\n",
        "        self.model = svm.OneClassSVM(nu=self.nu, kernel=self.kernel, gamma=self.gamma)\n",
        "        self.model.fit(X_train_scaled)\n",
        "        print(\"Model fitting completed.\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict species suitability for given environmental conditions\n",
        "        \"\"\"\n",
        "        if self.model is None or self.scaler is None:\n",
        "            raise ValueError(\"Model must be fitted before prediction\")\n",
        "\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        return self.model.decision_function(X_scaled)\n",
        "\n",
        "    def create_prediction_grid(self, raster_paths, grid_resolution=0.1,\n",
        "                              bounds=None, column_names=None):\n",
        "        \"\"\"\n",
        "        Create a prediction grid from environmental rasters\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        raster_paths : list\n",
        "            List of paths to environmental raster files\n",
        "        grid_resolution : float\n",
        "            Resolution of the prediction grid in degrees\n",
        "        bounds : tuple\n",
        "            (min_lon, min_lat, max_lon, max_lat) bounds for the grid\n",
        "        column_names : list\n",
        "            Names for the environmental variables\n",
        "        \"\"\"\n",
        "        if column_names is None:\n",
        "            column_names = [f'env_var_{i}' for i in range(len(raster_paths))]\n",
        "\n",
        "\n",
        "        if bounds is None:\n",
        "            with rasterio.open(raster_paths[0]) as src:\n",
        "                bounds = src.bounds\n",
        "                bounds = (bounds.left, bounds.bottom, bounds.right, bounds.top)\n",
        "\n",
        "        min_lon, min_lat, max_lon, max_lat = bounds\n",
        "\n",
        "\n",
        "        lons = np.arange(min_lon, max_lon, grid_resolution)\n",
        "        lats = np.arange(min_lat, max_lat, grid_resolution)\n",
        "        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
        "\n",
        "\n",
        "        coords_flat = np.column_stack([lon_grid.ravel(), lat_grid.ravel()])\n",
        "\n",
        "\n",
        "        env_data = []\n",
        "        for i, raster_path in enumerate(raster_paths):\n",
        "            try:\n",
        "                with rasterio.open(raster_path) as src:\n",
        "                    sampled_values = list(src.sample(coords_flat))\n",
        "                    values = [val[0] if val[0] != src.nodata else np.nan for val in sampled_values]\n",
        "                    env_data.append(values)\n",
        "                    print(f\"Sampled {column_names[i]}: {sum(~np.isnan(values))}/{len(values)} valid values\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error sampling from {raster_path}: {e}\")\n",
        "                env_data.append([np.nan] * len(coords_flat))\n",
        "\n",
        "\n",
        "        grid_df = pd.DataFrame({\n",
        "            'longitude': coords_flat[:, 0],\n",
        "            'latitude': coords_flat[:, 1]\n",
        "        })\n",
        "\n",
        "        for i, col_name in enumerate(column_names):\n",
        "            grid_df[col_name] = env_data[i]\n",
        "\n",
        "\n",
        "        grid_df_clean = grid_df.dropna()\n",
        "\n",
        "        return grid_df_clean, (lons, lats)\n",
        "\n",
        "    def evaluate_model(self, X_test, background_points_env=None, n_background=1000):\n",
        "        \"\"\"\n",
        "        Evaluate model performance using AUC\n",
        "        \"\"\"\n",
        "\n",
        "        pred_test = self.predict(X_test)\n",
        "\n",
        "        if background_points_env is None:\n",
        "            feature_mins = np.min(np.vstack([X_test, self.scaler.transform(X_test)]), axis=0)\n",
        "            feature_maxs = np.max(np.vstack([X_test, self.scaler.transform(X_test)]), axis=0)\n",
        "\n",
        "            background_points_env = np.random.uniform(\n",
        "                low=feature_mins, high=feature_maxs,\n",
        "                size=(n_background, X_test.shape[1])\n",
        "            )\n",
        "\n",
        "        pred_background = self.predict(background_points_env)\n",
        "\n",
        "        scores = np.concatenate([pred_test, pred_background])\n",
        "        y_true = np.concatenate([np.ones(len(pred_test)), np.zeros(len(pred_background))])\n",
        "\n",
        "\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_true, scores)\n",
        "        auc_score = metrics.auc(fpr, tpr)\n",
        "\n",
        "        return auc_score, fpr, tpr\n",
        "\n",
        "    def plot_distribution_map(self, grid_df, prediction_col='suitability',\n",
        "                             occurrence_data=None, figsize=(12, 8)):\n",
        "        \"\"\"\n",
        "        Plot the species distribution map\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=figsize)\n",
        "\n",
        "\n",
        "        scatter = plt.scatter(grid_df['longitude'], grid_df['latitude'],\n",
        "                            c=grid_df[prediction_col], cmap='Reds',\n",
        "                            s=1, alpha=0.6)\n",
        "        plt.colorbar(scatter, label='Habitat Suitability')\n",
        "\n",
        "        if occurrence_data is not None:\n",
        "            if 'coords_train' in occurrence_data:\n",
        "                plt.scatter(occurrence_data['coords_train'][:, 1],\n",
        "                          occurrence_data['coords_train'][:, 0],\n",
        "                          c='black', marker='^', s=20, label='Training', alpha=0.8)\n",
        "\n",
        "            if 'coords_test' in occurrence_data:\n",
        "                plt.scatter(occurrence_data['coords_test'][:, 1],\n",
        "                          occurrence_data['coords_test'][:, 0],\n",
        "                          c='blue', marker='x', s=20, label='Testing', alpha=0.8)\n",
        "\n",
        "            plt.legend()\n",
        "\n",
        "        plt.xlabel('Longitude')\n",
        "        plt.ylabel('Latitude')\n",
        "        plt.title(f'Species Distribution Model: {self.species_name or \"Unknown Species\"}')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        return plt.gcf()\n"
      ],
      "metadata": {
        "id": "lV-3h7Nt2yBy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(f'{PROJECT_DIR}/occurrences_and_environment.parquet')\n",
        "environmental_cols = ['temperature']#, 'temperature_sd']  # TODO: can we get these dynamically from the df?\n",
        "\n",
        "# Initialize  SDM\n",
        "sdm = MarineSpeciesDistributionModel(nu=0.1, kernel='rbf', gamma=0.5)\n",
        "sdm.species_name = 'Species'\n",
        "\n",
        "# Prepare the data\n",
        "data = sdm.prepare_data(df, environmental_cols)\n",
        "\n",
        "# Fit the model\n",
        "sdm.fit(data['X_train'])\n",
        "\n",
        "# Evaluate the model\n",
        "auc_score, fpr, tpr = sdm.evaluate_model(data['X_test'])\n",
        "print(f\"Model AUC Score: {auc_score:.3f}\")\n",
        "\n",
        "# TODO: fix grid to use LATMIN LONMAX etc\n",
        "\n",
        "# Create prediction grid\n",
        "grid_resolution = 0.01\n",
        "bounds = (LONMIN, LATMIN, LONMAX, LATMAX)\n",
        "\n",
        "# Create a simple prediction grid\n",
        "lons = np.arange(bounds[0], bounds[2], grid_resolution)\n",
        "lats = np.arange(bounds[1], bounds[3], grid_resolution)\n",
        "lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
        "\n",
        "grid_coords = np.column_stack([lon_grid.ravel(), lat_grid.ravel()])\n",
        "\n",
        "# Simulate environmental data for grid\n",
        "# TODO: should load data from WOA tif files?\n",
        "# file_path = f'{PROJECT_DIR}/woa23_decav_t00_04_t_mn.tif'\n",
        "# # Open the GeoTIFF file and read it into a numpy array\n",
        "# with rasterio.open(file_path) as src:\n",
        "#     data = src.read(1)  # Read the first band; use src.read() for all bands as a 3D array\n",
        "\n",
        "# grid_temperature = data\n",
        "\n",
        "grid_temperature = np.random.uniform(10, 25, len(grid_coords))\n",
        "#grid_salinity = np.random.uniform(32, 36, len(grid_coords))\n",
        "\n",
        "grid_env = np.column_stack([grid_temperature])  #[grid_salinity, grid_temperature])\n",
        "\n",
        "print('WOA:', grid_temperature.shape)\n",
        "print('simulated:', np.random.uniform(10, 25, len(grid_coords)).shape)\n",
        "\n",
        "# Make predictions\n",
        "predictions = sdm.predict(grid_env)\n",
        "\n",
        "# Create grid DataFrame\n",
        "grid_df = pd.DataFrame({\n",
        "    'longitude': grid_coords[:, 0],\n",
        "    'latitude': grid_coords[:, 1],\n",
        "#    'salinity': grid_salinity,\n",
        "    'temperature': grid_temperature,\n",
        "    'suitability': predictions\n",
        "})\n",
        "\n",
        "# Plot the results\n",
        "fig = sdm.plot_distribution_map(grid_df, occurrence_data=data)\n",
        "\n",
        "\n",
        "\n",
        "df_results = grid_df\n",
        "\n",
        "print(\"\\n Creating visualizations...\")\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.3f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "scatter = plt.scatter(\n",
        "    df_results['longitude'],\n",
        "    df_results['latitude'],\n",
        "    c=df_results['suitability'],\n",
        "    cmap='RdYlBu_r',\n",
        "    s=30,\n",
        "    alpha=0.7,\n",
        "    edgecolors='black',\n",
        "    linewidth=0.5\n",
        ")\n",
        "plt.colorbar(scatter, label='Habitat Suitability')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Habitat Suitability')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "RhDbu1Ht6SNj",
        "outputId": "0e3fb405-31b9-48c9-fc17-df66521911f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting One-Class SVM...\n",
            "Model fitting completed.\n",
            "Model AUC Score: 0.968\n",
            "WOA: (720, 1440)\n",
            "simulated: (58491,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "X has 1440 features, but StandardScaler is expecting 1 features as input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-38-77358640.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Create grid DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-33-1227644331.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model must be fitted before prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2965\u001b[0;31m         \u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2967\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2830\u001b[0m             \u001b[0;34mf\"X has {n_features} features, but {estimator.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m             \u001b[0;34mf\"is expecting {estimator.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 1440 features, but StandardScaler is expecting 1 features as input."
          ]
        }
      ]
    }
  ]
}